\documentclass[12pt]{article}

\usepackage{graphicx}
\usepackage{paralist}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{hhline}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{url}
\usepackage[left = 3cm, right = 3cm, top = 3cm]{geometry}


\pagestyle {plain}
\pagenumbering{arabic}

\newcounter{stepnum}

%% Comments

\usepackage{color}


\title{%
    Requirements Specification\\
    \large Artificial Facial Aging through Deep Neural Networks}
\author{Jessica de Leeuw, Sam Cymbaluk,\\
    Jeff Gibson, and Fanping Jiang}

\begin {document}

\maketitle


\newpage

\section {Domain}
Authors: Jessica de Leeuw and Jeff Gibson\\

\medskip

\noindent The current method for artificially aging a face in missing persons cases is flawed. The ability to produce an accurate projection with a single picture of the missing person is a powerful solution to this problem. The goal is to implement an algorithm that successfully produces a realistic interpretation of the individuals aged face. \\

Stakeholders would be parties such as the government, and other law enforcement services. The generation of aged faces is useful for tasks such as searching for missing persons. The Canadian government currently employs forensic artists to manually create projections of a missing person at a specific age. Images are generated through drawing, and a significant amount of information (such as pictures of family members) is required about the missing person. The expectation would be that a single image is required as input, and a fairly accurate representation of that person aged a certain number of years would be outputted.\\

The main entities which the domain is comprised of are machine learning, big data, and the artificial aging of human faces.\\

A machine learning approach will be used to perform the process of artificial facial aging. To generate accurately aged faces, a conditional Generative Adversarial Neural Network (cGAN) must be trained on big data. The machine learning domain is greatly affected by this project, as it will be the first project publicly available that performs artificial aging. On a similar note, if this project can generate sufficiently accurate images, it will drastically improve upon current techniques. This would make it a possibility that this technique could become the industry standard for artificial aging of human faces.\\

\section{Machine Learning Training}
Author: Sam Cymbaluk\\

\noindent The Machine Learning Training component handles the production of trained weights for the neural network used in this project.

\subsection{Functional Requirements}

\subsubsection{Data Set Retrieval and Preprocessing} \label{data retrieval}
The ML Training component will make a GCP storage bucket request to collect a preprocessed spacial data set stored as an HDF5 file.

\subsubsection{Training} \label{training}
The ML Training component takes the neural network architecture for this project along with the spacial database mentioned in \ref{data retrieval} and trains the network, updating the weights such that each iteration produces better predictions. The architecture and training will roughly follow what is described in this paper: \url{https://arxiv.org/abs/1702.01983}. At regular intervals a new version of the network architecture and weights should be saved to a file that can be later be used to restore the state of the network.

\subsubsection{Weights File Upload}
After training has been completed and a weights file like the one described in \ref{training}, the ML Training component will update the weights file with best performance by saving to a GCP storage bucket. This file can then be manually downloaded and given to the ML Inference component.

\subsection{Non-Functional Requirements}

\subsubsection {Reliability}

Reliability is one of the most important non-functional requirements for this component. The training of the neural network is a process that can take days. For this reason, it is important that any errors are handled gracefully so that progress can be resumed as seamlessly as possible.

\subsubsection {Accuracy of Results}
 
The results of training are not either correct or incorrect; rather, the algorithm itself computes the accuracy and uses this value to make incremental improvements throughout the training process.

\subsubsection {Performance}

The issue of performing efficient tensor calculations is offloaded to the third-party library Tensorflow. However, we must still ensure that the other main source of bottlenecks, the data pipeline, is being handled efficiently. This means that data should be queued in memory so it is available for the network to train on as soon as it is requested.

\subsubsection {Portability Issues}

Deep learning in Tensorflow requires a large number of programs, libraries, and drivers to all be installed with exactly correct versions to function correctly and efficiently. In order to reduce the number of potential headaches and to increase the portability of our solution, we will package the component in a Python PIP module to make installing the necessary packages automatic.

\subsection{Requirements for the Development \& Maintenance\\ Process}

\subsubsection {Quality Control Procedures}

Unit tests will be written for the most crucial functions like the loss function and data loading procedure. This will ensure that time spent training produces useful results.

\subsubsection {Priorities of the Required Functions}

The main priority of the required functions are to be as reliable as possible. Like previously mentioned, the training component will often be running for 10s of hours and will need to handle any errors it encounters during execution gracefully to prevent the loss of progress.

\subsubsection {Likely Changes to System Maintenance Procedures}

There are two anticipated phases to the system maintenance:
\begin{enumerate}
    \item Research \& Development which will consist of less structured development until an initial viable model is obtained.
    \item Continued Development which will consist of improving our viable model into a fully fledged component that includes modularized code to promote maintainability.
\end{enumerate}

\section{Data Storage}
Author: Jeff Gibson\\

\noindent Component Description\\

The data storage component is concerned with how data will be stored and indexed throughout the project.

\subsection{Functional Requirements}

\subsubsection{Data Processing} \label{data processing}

Only ``clean" data from the datasets will be uploaded to the cloud for training. ``Clean" data
is defined as members that meet the following criteria:\\

\begin{enumerate}
    \item Image must be of size 64px X 64px or greater
    \item Isolated face must occupy at least 50\% of the total image size
\end{enumerate}

\subsubsection{Cloud Storage}

Data will be preprocessed locally and uploaded as a spatial
database to the google cloud bucket so that
it is easily accessible for training. Along with the data, trained versions of the algorithm
will be stored on the cloud. 

\subsection{Non-Functional Requirements}

\subsubsection {Reliability}

It is very important that data is not lost, and does not become corrupt. To ensure this the hdf5 file is stored on
the Google Cloud Platform (GCP).

\subsubsection {Performance}

As training is already a very long process it is important that the database is not a bottleneck with long lookup times. To ensure that performance is acceptable the spatial database has constant lookup times, and because data is preprocessed, the overhead during training is reduced.

\subsubsection {Physical Constraints}

To work around the large storage space requirements, the project will utilize a GCP cloud bucket
storage space.

\subsubsection {Portability Issues}

This is not a concern. Since it is a database, there is no reason to move it.

\subsection{Requirements for the Development \& Maintenance\\  Process}

\subsubsection {Quality Control Procedures}

Ensure that the spatial database is storing data correctly and in the correct format. To accomplish this, a small
sample of the data was uploaded initially and tested
to ensure that the images could be loaded successfully. 

\subsubsection {Likely Changes to System Maintenance Procedures}

In the future, when time is not a constraint, we hope to 
switch from a spatial database to a more maintainable SQL database hosted on the google cloud platform.

\section{Front-end Interface}
Author: Fanping Jiang\\

\noindent The Front-end Interface module is for user to input data and receive prediction.

\subsection{Functional Requirements}
\subsubsection{UI}
Basic User Interface design with only image file input button, time period text box, a click button and a window for retrieving image prediction.
\subsubsection{Input}\label{input}
The interface takes facial image with targeted aging period as input data. Raise error if any input is improper in any manners.
\subsubsection{Output}
The interface returns aged face after the given time period as prediction. There may be delay depend on back end response time.

\subsection{Non-Functional Requirements}

\subsubsection {Usability}

The designing should be brief but complete.

\subsubsection {Portability}

This interface should be capable across platforms.

\subsubsection {Extensibility}
 
Our implementation need flexibility to extend when future features are added.

%\subsection{Requirements for the Development \& Maintenance\\ Process}

\section{Machine Learning Inference}
Author: Jessica de Leeuw\\

\subsection{Functional Requirements}

The machine learning inference is what provides the services to the client. It holds the value that the user wishes to obtain.\\

The ML Inference will consist of a back-end that handles the trained version of the machine learning model. It will provide the inference services to the front-end. The end-user will input an image that has never been seen before by the ML model, and the model will output a prediction based on its training. It is essentially an API that the front-end will call.\\

The API will take an image of a person, and return an image of that same person. If it is fully functional, it will return a face that has been aged by a certain amount of years.

\subsection{Non-Functional Requirements}

\subsubsection {Reliability}

The ML Inference will have to reliably perform for the user. This means that it will respond to the user in an adequate amount of time, and that it will be guaranteed to not crash when it is called.

\subsubsection {Accuracy of Results}

It is important that results are accurate, otherwise the resultant photo has no use to the client. The accuracy of the photos that the network outputs will be determined during the ML training stage. The accuracy of the output of the client's photo can only be verified by the client themselves.

\subsubsection {Performance}

Requests will be sent to the back-end, which is on the GCP. This will guarantee high performance, as it has a significant amount of resources.

\subsubsection {Human-Computer Interface Issues}

This is handled solely by the front-end.

\subsubsection {Physical Constraints}

There are no physical constraints for the ML Inference.

\subsubsection {Portability Issues}

Deep learning in Tensorflow requires a large number of programs, libraries, and drivers to all be installed with exactly correct versions to function correctly and efficiently. In order to increase the portability of our solution, the back-end will be hosted on the GCP.

\subsection{Requirements for the Development \& Maintenance\\ Process}

\subsubsection {Quality Control Procedures}

The efficiency and functioning of the ML Inference will be tested before being available to end-users through methods such as using a mock client (this is achieved through the used of applications such as Postman).

\subsubsection {Likely Changes to System Maintenance Procedures}

Likely changes would include updating the ML Inference if there is more training done and more accurate results from the neural network.

\end{document}
